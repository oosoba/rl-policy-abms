{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-vs-(N-k) Flu ABM Env\n",
    "- k-vs-(N-k) experiment\n",
    "- Kicking tires on multiplayer instance of Flu ABM with RL learners \n",
    "- Basic indepRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools, importlib, sys, warnings, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML libs\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "log_path = './log/flu'\n",
    "#tensorboard --logdir=flugame_worker_1:'./log/train_rf_flugame_worker'\n",
    "\n",
    "## suppress annoy verbose tf msgs\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # '3' to block all including error msgs\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./embodied_arch')\n",
    "\n",
    "import embodied_indep as emi \n",
    "import flumodel_python.flu_env as Fenv\n",
    "from embodied_misc import ActionPolicyNetwork, SensoriumNetworkTemplate, ValueNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exos = [1,2,3,10]  # (np.random.sample(9223) < 0.3)\n",
    "exos = (np.random.sample(9223) < 0.004)\n",
    "exos = [j for j in range(len(exos)) if exos[j]==True]\n",
    "print(len(exos))\n",
    "\n",
    "importlib.reload(Fenv);\n",
    "importlib.reload(emi);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "flu_menv = Fenv.Flu_env(\n",
    "    exo_idx=exos,\n",
    "    model_path=\"./flumodel_python/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flu_menv.actor_count)\n",
    "print(flu_menv.state_space_size, flu_menv.action_space_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MARL Setup Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = lambda s: ActionPolicyNetwork(s, hSeq=(8,), gamma_reg=1e-1)\n",
    "value = lambda s: ValueNetwork(s, hSeq=(8,), gamma_reg=1.)\n",
    "sensor = lambda st, out_dim: SensoriumNetworkTemplate(st, hSeq=(16,8,8), out_dim=out_dim, gamma_reg=5.)\n",
    "\n",
    "# num_episodes, n_epochs, max_len = (100, 1501, 25)\n",
    "# num_episodes, max_len, n_epochs, evry = (100, 35, 1501, 300)\n",
    "# num_episodes, max_len, n_epochs, evry = (10, 15, 400, 100)\n",
    "num_episodes, max_len, n_epochs, evry = (100, 35, 501, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flumrf = emi.EmbodiedAgent_IRFB(\n",
    "    name=\"flu_mRFB\", env_=flu_menv,\n",
    "    alpha_p=150, alpha_v=50., latentDim=4,\n",
    "    max_episode_length=max_len, _every_=evry, \n",
    "    actorNN=actor, valueNN=value, sensorium=sensor\n",
    ")\n",
    "(flumrf.a_size, flumrf.env.action_space_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "flumrf.init_graph(sess) # note tboard log dir\n",
    "saver = tf.train.Saver(max_to_keep=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Baselining untrained pnet...')\n",
    "rwds0 = []\n",
    "acts_cov = np.zeros([flumrf.actor_count,flumrf.actor_count])\n",
    "for k in range(num_episodes):\n",
    "    flumrf.play(sess, terminal_reward=0.);\n",
    "    rwds0.append(flumrf.last_total_returns)\n",
    "    actions = np.array(flumrf.episode_buffer['actions']).T\n",
    "    acts_cov = acts_cov + (np.cov(actions)/num_episodes)\n",
    "    print(\"\\rEpisode {}/{}\".format(k, num_episodes),end=\"\")\n",
    "\n",
    "# Compute average rewards\n",
    "base_perf = 100.*np.mean(np.array(rwds0)/float(flumrf.max_episode_length))\n",
    "base_per_agent = 100.*np.mean(np.array(rwds0)/float(flumrf.max_episode_length), axis=0)\n",
    "\n",
    "print(\"\\nAgent is flu-free for an average of {}pct of seasons\".format(\n",
    "    1.*base_perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_corr = acts_cov.copy()\n",
    "jm, km = acts_corr.shape\n",
    "for j in range(jm):\n",
    "    for k in range(km):\n",
    "        denom = np.sqrt((acts_corr[j,j])*(acts_corr[k,k]))\n",
    "        acts_corr[j,k] = acts_corr[j,k]/denom\n",
    "\n",
    "print(\"Agent Action Correlations:\")\n",
    "sns.heatmap(acts_corr, center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Agent Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Train Agents\n",
    "print('Training...')\n",
    "hist = flumrf.work(sess, num_epochs=n_epochs, saver=saver)\n",
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pnet!\n",
    "print('Testing...')\n",
    "rwds = []\n",
    "acts_cov_trained = np.zeros([flumrf.actor_count,flumrf.actor_count])\n",
    "for k in range(num_episodes):\n",
    "    flumrf.play(sess)\n",
    "    rwds.append(flumrf.last_total_returns)\n",
    "    actions = np.array(flumrf.episode_buffer['actions']).T\n",
    "    acts_cov_trained = acts_cov_trained + (np.cov(actions)/num_episodes)\n",
    "    print(\"\\rEpisode {}/{}\".format(k, num_episodes),end=\"\")\n",
    "\n",
    "trained_perf = 100.*np.mean(np.array(rwds)/float(flumrf.max_episode_length))\n",
    "trained_per_agent = 100.*np.mean(np.array(rwds)/float(flumrf.max_episode_length), axis=0)\n",
    "\n",
    "print(\"\\nAgent is flu-free for an average of {} pct compared to baseline of {} pct\".format(\n",
    "    1.*trained_perf, 1.*base_perf) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_corr_trained = acts_cov_trained.copy()\n",
    "jm, km = acts_corr_trained.shape\n",
    "for j in range(jm):\n",
    "    for k in range(km):\n",
    "        denom = np.sqrt((acts_cov_trained[j,j])*(acts_cov_trained[k,k]))\n",
    "        acts_corr_trained[j,k] = acts_corr_trained[j,k]/denom\n",
    "\n",
    "mask = np.zeros_like(acts_corr_trained)\n",
    "mask[np.triu_indices_from(mask,k=0)] = True\n",
    "with sns.axes_style(\"darkgrid\"):\n",
    "    plt.rcParams['figure.figsize'] = (15, 12)\n",
    "    ax = sns.heatmap(acts_corr_trained, \n",
    "                     mask=mask, vmax=0.125, center=0)\n",
    "    ax.set_ylabel(\"Agent Index\")\n",
    "    ax.set_xlabel(\"Agent Index\")\n",
    "    ax.set_title(\"Action Correlations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rwds0_df = pd.DataFrame(100.*(np.array(rwds0)/float(flumrf.max_episode_length)))\n",
    "rwds_df = pd.DataFrame(100.*(np.array(rwds)/float(flumrf.max_episode_length)))\n",
    "\n",
    "rwds0_df['Wave'] = \"Baseline\"\n",
    "rwds_df['Wave'] = \"Trained\"\n",
    "\n",
    "resDF = pd.concat([rwds0_df, rwds_df])\n",
    "resDF.columns = [\"Agent\"+str(tc) if tc is not \"Wave\" else tc for tc in resDF.columns]\n",
    "# resDF['id'] = resDF.index\n",
    "print(resDF.shape)\n",
    "# resDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "resDF = resDF.melt(\n",
    "    id_vars=['Wave'], #['id', 'Wave'],\n",
    "    value_vars=[tc for tc in resDF.columns if \"Agent\" in tc]\n",
    ")\n",
    "resDF = resDF.rename(columns={\"variable\": \"Agent\", \"value\": \"Immune_pct\"})\n",
    "print(resDF.shape)\n",
    "\n",
    "res_tabs = resDF.groupby(['Agent','Wave']).aggregate(['mean','std']) # res_tabs\n",
    "\n",
    "# resDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (9, 35)\n",
    "sns.set(font_scale=1.25)\n",
    "\n",
    "fig = sns.violinplot(data=resDF, inner=\"box\", cut=0,\n",
    "                     x=\"Immune_pct\", y=\"Agent\", hue=\"Wave\",\n",
    "                     split=True);\n",
    "fig.set_title(\n",
    "    'Average Episode Rewards: Baseline vs Trained Agents.');\n",
    "fig.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "base_meanDF = resDF[resDF.Wave==\"Baseline\"].groupby(['Agent']).aggregate(['mean'])\n",
    "base_meanDF.sort_index(inplace=True)\n",
    "\n",
    "trained_meanDF = resDF[resDF.Wave==\"Trained\"].groupby(['Agent']).aggregate(['mean'])\n",
    "trained_meanDF.sort_index(inplace=True)\n",
    "\n",
    "mean_diffDF = (trained_meanDF - base_meanDF)\n",
    "mean_diffDF.columns = ['Mean_Immune_Pct_Change']\n",
    "# mean_diffDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (9, 19)\n",
    "sns.set_color_codes(\"dark\")\n",
    "fig, axs = plt.subplots(2,1, sharex=True, gridspec_kw={'height_ratios': [1,4]})\n",
    "cmp = sns.violinplot(x='Mean_Immune_Pct_Change', cut=0, inner='quartile',\n",
    "                     data=mean_diffDF, ax=axs[0])\n",
    "axs[0].set_ylabel('Agent Aggregate');\n",
    "axs[0].set_title(\n",
    "    'Distribution of Changes in Flu Immunity Rates:\\nIn Aggregate & Per-Agent.'\n",
    ");\n",
    "\n",
    "sns.barplot(y=mean_diffDF.index, x=\"Mean_Immune_Pct_Change\", \n",
    "            data=mean_diffDF, color=\"r\",\n",
    "            label=\"Success Rate\", ax=axs[1]);\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "axs[1].set_xlabel('Avg. Change in Immunity Rates');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
